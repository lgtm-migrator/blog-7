{
  
    
        "post0": {
            "title": "OS Interview Prep Resources",
            "content": "Concepts . NPTEL Link | Youtube playlist link | . Questions . Topic wise questions | .",
            "url": "https://rohanrajpal.com/interview/2020/07/15/OS-interview-prep.html",
            "relUrl": "/interview/2020/07/15/OS-interview-prep.html",
            "date": " • Jul 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "The Virtual Internship: My Experience.",
            "content": "These summers, I interned at one of the largest travel companies of the world, Expedia Group™️. Who knew during a pandemic when travel is at an all time low, Expedia had a great intern program planned for us! . Luckily, my previous intern was remote too, so I was kind of used to work from home. In this internship, I majorly worked on cloud and data engineering. . . The induction week . Expedia organized an induction week for us, and it involved workshops on various topics: how to become a better leader, designer, and we even got to know how Expedia operates. We kept on having workshops throughout our intern, and there was a lot to learn from each session. . My setup . Not the fanciest setup out there, but enough to get the work done :) My Team - Vrbo: Stayx dot net modernization pod . I was a part of the Stay Experience team, which looks after the post-booking experience for a traveller. The team was divided into pods, and I worked on the .Net Stack Modernisation pod. My work involved making a microservice and figuring out how to deploy it to the cloud. I worked with a manager and a buddy. We synced up every week and discussed work updates every day. It motivated me to stay on track. I also synced up with our project sponsor a few times. I enjoyed such one on one sessions. They helped me connect with the team better. All the Vrbo interns together had a weekly sync with the Vrbo managers. We socialized, played some games, get help on some issues. It was nice to have someone for support throughout the program, and these calls also helped me get to know the other interns better. . The project . Motivation . We have a database which stores the notifications for guests of guests in a homestay. Now we wanted a way in which we can store the data in S3 and keep it updated. . Why are you storing the data in two different places? This data is not only used to send a notification but also by an analyst or data scientist. The MongoDB database also backs the GoG API, and if everyone does their operations on MongoDB, it might severely affect the API. | . | . We finally came up with the idea to use a Spark Job. This job would take the data from MongoDB and store it in an S3 bucket. . Why a spark job? Spark and Scala are the industry standard for data management. The jobs will be able to manage huge amounts of data without any hiccups. | . | . Aim: Create a spark job to sync data from MongoDB to S3 . A quick revision . This blog is going to get more technical now, just keeping this for a quick reference if you have a doubt. . What’s MongoDB? It’s a NoSQL database. What’s scala? It’s a programming language widely used for data management. I did all my coding in the Scala language. What’s Apache spark? It’s a fast and general-purpose cluster computing system for large scale data processing. Some important things to know about spark are: . Dataframe: This is data in the form of a table, just like a relational database table. | Dataset: Extension of Dataframes, they provide the functionality of being type-safe and an object-oriented programming interface. | SparkSession vs SparkContext: Spark session is a unified entry point of a spark application from Spark 2.0. It provides a way to interact with various spark’s functionality with a lesser number of constructs. Instead of having a spark context, hive context, SQL context, now all of it is encapsulated in a Spark session | Prior Spark 2.0, Spark Context was the entry point of any spark application and used to access all spark features and needed a sparkConf which had all the cluster configs and parameters to create a Spark Context object | . What’s a spark job? In a spark application, when you invoke an action on RDD, a job is created. It’s the main function that has to be done and submitted to spark. What’s a vault? Hashicorp Vault is a tool for secrets management, encryption as a service, and privileged access management. What’s an S3 bucket? Just a simple distributed file storage system, think of it like the hard disk on your computer . The technology stack Approach . . The spark job . Authenticates the vault and gets the secrets | Reads the updated data from MongoDB | Reads the data stored as parquet in S3 bucket | Does a left anti join on s3 and mongo data, you now have the data that did not change | Merge the data that didn’t change with the new data with the new data | Write the data as parquet in S3 bucket | . The authentication was a little better than just sending a saved token: . Grab the EC2 metadata and nonce | Send the metadata and nonce to Vault | Vault checks if the EC2 instance is allowed and the nonce is correct | Obtain secrets like AWS access and secret key, and MongoDB password | Send a nonce to the Vault server and get the token | Get the secrets via the token | . Here’s a nice example explaining everything: . Mongo id author book updateTime 1 A1 B1 T1 2 A2 B2 T2 3 A3 B3 T3 4 A4 B4 T4 S3 1 A1 B1 T1 2 A2 B2 T2 3 A3 B3 T2.1 Step 1: get all docs from mongoDb between updateTime1 and updateTime2 where T2 &lt; updateTime1 &lt; updateTime2 fetched records: 3 A3 B3 T3 4 A4 B4 T4 Step 2: read all records from S3. fetched records: 1 A1 B1 T1 2 A2 B2 T2 3 A3 B3 T2.1 Step 3: Left anti join on id between S3 and mongo data so that we have the data that did not change 1 A1 B1 T1 2 A2 B2 T2 Step 4: Merge results of Step 3 with data fetched in Step 1: new data set: 1 A1 B1 T1 2 A2 B2 T2 3 A3 B3 T3 4 A4 B4 T4 This can be put back to S3. You can see how this data is in sync with Mongo data . Challenges (and how I tackled them) . . VPN Issues: The VPN I was using did not support Linux or WSL, so I had to work on windows. Windows is not at all developer-friendly. It was challenging to find a workaround for one-line commands in Linux. However, I found a hack for this. I created an EC2 instance on the Expedia network and shifted all my work to that. Not only I could access all the links, but the scripts ran much faster than on my computer. | . | RAM Issues: I initially was using IntelliJ since it was easier to setup a scala project with it. Intellij was terribly slow and took a lot of RAM. I later switched to VSCode plus Metals. Although it was a little more time consuming to setup, once understood, all RAM issues were solved, additionally using bloop instead of sbt decreased compile time. | Having a local MongoDB server for testing was also quite RAM hungry, MongoDB Atlas helped me a lot here. I deployed a free cluster in the cloud, and my work was done :) | . | Spark and MongoDB Spark has some underlying concepts which were a little nontrivial to understand, at least for a first-timer like me. Above that the documentation of MongoDB-Spark connector was following old spark conventions at one place and new ones somewhere else. The documentation confused me a bit. | . | Understanding Vault EC2 authentication Authentication took most of the time, being a college student, I really didn’t worry about securing my applications in projects. Since we really didn’t put something into production. | I learned about Hashicorp Vault(Store secrets), Terraform(Build instances from code) and Consul(Backend for Vault) | Rather than having a token to authenticate vault and get the secrets, a better method would be to use the ec2 metadata in which the spark job will be running to authenticate vault. | Making EC2 instances with Terraform and Consul | . | Setting up EC2 instances I had some trouble finding the correct configurations so that I am able to SSH into an instance and make sure the instance can access all VPN links. | . | .",
            "url": "https://rohanrajpal.com/internship/2020/07/13/expedia-internship-experience.html",
            "relUrl": "/internship/2020/07/13/expedia-internship-experience.html",
            "date": " • Jul 13, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "DBMS Interview Prep Resources",
            "content": "Concepts . Basic of DBMS, Relational Algebra and SQL . Playlist link | . Transaction Management . Playlist link | . B+ Trees . Problems . Topic wise DBMS questions | .",
            "url": "https://rohanrajpal.com/interview/2020/07/10/DBMS-interview-prep.html",
            "relUrl": "/interview/2020/07/10/DBMS-interview-prep.html",
            "date": " • Jul 10, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Triplet Training for Generative Adversarial Networks",
            "content": "What will I get from this blog? . By the end of this blog we&#39;ll be able to make a model that can generate the below numers from random noise . . Introduction . This is an implementation of the paper:Zieba, Maciej, and Lei Wang. &quot;Training triplet networks with gan.&quot; arXiv preprint arXiv:1704.02227 (2017). . What is triplet training? . Triplet training helps us learn distributed embeddings by the notion of similarity and dissimilarity. Read more about it here . This paper replaces triplet loss with the classification losss of the discriminator and compares the results. . Approach . I initially pretrained the GAN with the original GAN objective, for 50 epochs. Post that I train with the Improved GAN objective for 10 epochs. . The discriminator of the GAN generates M features, we take these M features and put it into the classifier. For classification I have used a 9-nearest neighbour classifier. . Imports . #collapse-hide # Reference # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html # https://github.com/andreasveit/triplet-network-pytorch !pip install livelossplot &gt; /tmp/xxy import math import os import sys from pathlib import Path from pprint import pprint import numpy as np from PIL import Image from scipy.spatial.distance import cdist # from torch import cdist from sklearn import preprocessing from sklearn.metrics import average_precision_score from sklearn.neighbors import KNeighborsClassifier from tqdm.auto import tqdm as tq import torch import torch.nn as nn import torch.optim as optim from livelossplot import PlotLosses from torch.nn import functional as F from torch.nn.parameter import Parameter from torch.utils.data import DataLoader, Dataset, TensorDataset from torchvision import datasets, transforms from torchvision.utils import save_image import matplotlib.pyplot as plt . . References . #collapse-hide # https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py # https://www.kaggle.com/hirotaka0122/triplet-loss-with-pytorch # https://github.com/openai/improved-gan/blob/master/mnist_svhn_cifar10/train_mnist_feature_matching.py # https://github.com/adambielski/siamese-triplet/blob/master/Experiments_MNIST.ipynb # https://github.com/eladhoffer/TripletNet # https://stackoverflow.com/questions/26210471/scikit-learn-gridsearch-giving-valueerror-multiclass-format-is-not-supported . . Utils . I combined all the handy functions used throughout the notebook into one place, for easier access. . #collapse-hide class Arguments(): def __init__(self): self.batch_size=100 self.epochs=10 self.lr=0.003 self.momentum=0.5 self.cuda=torch.cuda.is_available() self.seed=1 self.log_interval=100 self.save_interval=5 self.unlabel_weight=1 self.logdir=&#39;./logfile&#39; self.savedir=&#39;./models&#39; self.load_saved=True args = Arguments() np.random.seed(args.seed) torch.manual_seed(args.seed) results = {} def log_sum_exp(x, axis = 1): m = torch.max(x, dim = 1)[0] return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis)) def reset_normal_param(L, stdv, weight_scale = 1.): assert type(L) == torch.nn.Linear torch.nn.init.normal(L.weight, std=weight_scale / math.sqrt(L.weight.size()[0])) def show_gen_images(gan): num_images=4 arr = gan.draw(num_images) square_dim = num_images//2 f, axarr = plt.subplots(square_dim,square_dim) # f.set_figheight(10) # f.set_figwidth(10) for i in range(square_dim): for j in range(square_dim): axarr[i,j].imshow(arr[i*square_dim+j],cmap=&#39;gray&#39;) axarr[i,j].axis(&#39;off&#39;) # https://github.com/Sleepychord/ImprovedGAN-pytorch/blob/master/functional.py#L13 class LinearWeightNorm(torch.nn.Module): def __init__(self, in_features, out_features, bias=True, weight_scale=None, weight_init_stdv=0.1): super(LinearWeightNorm, self).__init__() self.in_features = in_features self.out_features = out_features self.weight = Parameter(torch.randn(out_features, in_features) * weight_init_stdv) if bias: self.bias = Parameter(torch.zeros(out_features)) else: self.register_parameter(&#39;bias&#39;, None) if weight_scale is not None: assert type(weight_scale) == int self.weight_scale = Parameter(torch.ones(out_features, 1) * weight_scale) else: self.weight_scale = 1 def forward(self, x): W = self.weight * self.weight_scale / torch.sqrt(torch.sum(self.weight ** 2, dim = 1, keepdim = True)) return F.linear(x, W, self.bias) def __repr__(self): return self.__class__.__name__ + &#39;(&#39; + &#39;in_features=&#39; + str(self.in_features) + &#39;, out_features=&#39; + str(self.out_features) + &#39;, weight_scale=&#39; + str(self.weight_scale) + &#39;)&#39; . . Datasets . Below is the MNIST dataset. It has 60,000 training and 10,000 testing samples. The labelled set has N (100 or 200) samples and the unlabelled set had all 60,000 samples. . #collapse-hide # Reference https://github.com/Sleepychord/ImprovedGAN-pytorch/blob/master/Datasets.py def MNISTLabel(class_num): raw_dataset = datasets.MNIST(&#39;../data&#39;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), ])) class_tot = [0] * 10 data = [] labels = [] tot = 0 perm = np.random.permutation(raw_dataset.__len__()) for i in range(raw_dataset.__len__()): datum, label = raw_dataset.__getitem__(perm[i]) if class_tot[label] &lt; class_num: data.append(datum.numpy()) labels.append(label) class_tot[label] += 1 tot += 1 if tot &gt;= 10 * class_num: break times = int(np.ceil(60_000 / len(data))) return TensorDataset(torch.FloatTensor(np.array(data)).repeat(times,1,1,1), torch.LongTensor(np.array(labels)).repeat(times)) def MNISTUnlabel(): raw_dataset = datasets.MNIST(&#39;../data&#39;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), ])) return raw_dataset def MNISTTest(): return datasets.MNIST(&#39;../data&#39;, train=False, download=True, transform=transforms.Compose([ transforms.ToTensor(), ])) # Reference https://github.com/adambielski/siamese-triplet/blob/master/datasets.py#L79 class MNISTTriplet(Dataset): def __init__(self, mnist_dataset): self.mnist_dataset = mnist_dataset.tensors self.train_labels = self.mnist_dataset[1] self.train_data = self.mnist_dataset[0] self.labels_set = set(self.train_labels.numpy()) self.label_to_indices = {} for label in self.labels_set: self.label_to_indices[label] = np.where(self.train_labels.numpy() == label)[0] def __getitem__(self, index): img1, label1 = self.train_data[index], self.train_labels[index].item() positive_index = index while positive_index == index: positive_index = np.random.choice(self.label_to_indices[label1]) negative_label = np.random.choice(list(self.labels_set - set([label1]))) negative_index = np.random.choice(self.label_to_indices[negative_label]) img3 = self.train_data[negative_index] img2 = self.train_data[positive_index] return img1, img2, img3 def __len__(self): return len(self.mnist_dataset[1]) # Reference https://github.com/adambielski/siamese-triplet/blob/master/losses.py class TripletLoss(nn.Module): def __init__(self): super(TripletLoss, self).__init__() def forward(self, anchor, positive, negative, size_average=True): d_positive = torch.sqrt(torch.sum((anchor - positive).pow(2),axis=1)) d_negative = torch.sqrt(torch.sum((anchor - negative).pow(2),axis=1)) z = torch.cat((d_positive.unsqueeze(1),d_negative.unsqueeze(1)),axis=1) z = log_sum_exp(z) return -torch.mean(d_negative) + torch.mean(z) MNISTUnlabel() MNISTTest() . . Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw Processing... Done! . /opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. . Dataset MNIST Number of datapoints: 10000 Root location: ../data Split: Test StandardTransform Transform: Compose( ToTensor() ) . GAN . Architecture: Generator and Discriminator . This notebook follows the architecture used in Improved GAN (Salimans et al. 2016). The discriminator outputs M (16 or 32) features. The hyperparameters are same as in TripletGAN. . #collapse-hide # https://github.com/Sleepychord/ImprovedGAN-pytorch/blob/master/Nets.py class Discriminator(nn.Module): def __init__(self, input_dim = 28 ** 2, output_dim = 10): super(Discriminator, self).__init__() self.input_dim = input_dim self.output_dim = output_dim self.layers = torch.nn.ModuleList([ LinearWeightNorm(input_dim, 1000), LinearWeightNorm(1000, 500), LinearWeightNorm(500, 250), LinearWeightNorm(250, 250), LinearWeightNorm(250, 250)] ) self.final = LinearWeightNorm(250, output_dim, weight_scale=1) self.reduce = nn.Sequential( nn.Linear(self.output_dim, 1), nn.Sigmoid(), ) def forward(self, x, feature = False, pretrain=False): x = x.view(-1, self.input_dim) noise = torch.randn(x.size()) * 0.3 if self.training else torch.Tensor([0]) if args.cuda: noise = noise.cuda() x = x + noise for i in range(len(self.layers)): m = self.layers[i] x_f = F.relu(m(x)) noise = torch.randn(x_f.size()) * 0.5 if self.training else torch.Tensor([0]) if args.cuda: noise = noise.cuda() x = (x_f + noise) if feature: return x_f out = self.final(x) if pretrain: out = self.reduce(out) return out class Generator(nn.Module): def __init__(self, z_dim, output_dim = 28 * 28): super(Generator, self).__init__() self.z_dim = z_dim self.fc1 = nn.Linear(z_dim, 500, bias = False) self.bn1 = nn.BatchNorm1d(500, affine = False, eps=1e-6, momentum = 0.5) self.fc2 = nn.Linear(500, 500, bias = False) self.bn2 = nn.BatchNorm1d(500, affine = False, eps=1e-6, momentum = 0.5) self.fc3 = LinearWeightNorm(500, output_dim, weight_scale = 1) self.bn1_b = Parameter(torch.zeros(500)) self.bn2_b = Parameter(torch.zeros(500)) nn.init.xavier_uniform_(self.fc1.weight) nn.init.xavier_uniform_(self.fc2.weight) def forward(self, batch_size, draw=None): if draw is None: x = torch.rand(batch_size, self.z_dim) else: x = draw if args.cuda: x = x.cuda() x = F.softplus(self.bn1(self.fc1(x)) + self.bn1_b) x = F.softplus(self.bn2(self.fc2(x)) + self.bn2_b) x = F.softplus(self.fc3(x)) return x . . GAN Class . For pretraining the GAN, I have followed the standard objective (Goodfellow, Ian, et al. 2014) . #collapse-hide # Reference: https://github.com/Sleepychord/ImprovedGAN-pytorch/blob/master/ImprovedGAN.py class ImprovedGAN(object): def __init__(self, G, D, labeled, unlabeled, test): self.G = G self.D = D # if(args.mode == &#39;train&#39;): g_name = &#39;G_&#39;+str(D.output_dim)+&#39;_&#39;+str(args.labeled)+&#39;.pkl&#39; d_name = &#39;D_&#39;+str(D.output_dim)+&#39;_&#39;+str(args.labeled)+&#39;.pkl&#39; # else: g_name_pretrain = &#39;pretrain&#39; + &#39;_G_&#39;+str(D.output_dim)+&#39;.pkl&#39; d_name_pretrain = &#39;pretrain&#39; + &#39;_D_&#39;+str(D.output_dim)+&#39;.pkl&#39; if args.mode == &#39;pretrain&#39;: self.g_path = Path(args.savedir) / g_name_pretrain self.d_path = Path(args.savedir) / d_name_pretrain else: self.g_path = Path(args.savedir) / g_name self.d_path = Path(args.savedir) / d_name if os.path.exists(args.savedir) and args.load_saved: print(&#39;Loading model &#39; + args.savedir) if False and os.path.exists(self.g_path): self.G.load_state_dict(torch.load(self.g_path)) self.D.load_state_dict(torch.load(self.d_path)) else: print(&#39;Loaded pretrain&#39;) self.G.load_state_dict(torch.load(Path(args.savedir) / g_name_pretrain)) self.D.load_state_dict(torch.load(Path(args.savedir) / d_name_pretrain)) else: print(&#39;Creating model&#39;) if not os.path.exists(args.savedir): os.makedirs(args.savedir) torch.save(self.G.state_dict(), self.g_path) torch.save(self.D.state_dict(), self.d_path) # self.writer = tensorboardX.SummaryWriter(log_dir=args.logdir) if args.cuda: self.G.cuda() self.D.cuda() self.Doptim = optim.Adam(self.D.parameters(), lr=args.lr, betas= (args.momentum, 0.999)) self.Goptim = optim.Adam(self.G.parameters(), lr=args.lr, betas = (args.momentum,0.999)) self.knn = KNeighborsClassifier(n_neighbors=9) self.tripletloss = TripletLoss() self.drawnoise = torch.rand(4, self.G.z_dim) self.labeled = labeled self.unlabeled = unlabeled self.test = test def get_features(self,dataset): loader = DataLoader(dataset, batch_size = args.batch_size, shuffle=True, drop_last=True, num_workers = 4) X = [] y = [] for (data,label) in loader: data = data.cuda() X += self.D(data) y += label # del data del loader,data X = torch.stack(X).data.cpu().numpy() y = torch.LongTensor(y).data.cpu().numpy() # X = torch.stack(X) # y = torch.LongTensor(y) return X,y def trainknn(self): X,y = self.get_features(self.unlabeled) self.knn.fit(X,y) print(&quot;Fit done&quot;) del X,y def calc_mAP(self,test_features, testy, train_features, trainy): Y = cdist(test_features,train_features) ind = np.argsort(Y,axis=1) print(&quot;Done argsort&quot;) del Y,train_features prec = 0.0 num_classes = 10 acc = [0.0] * num_classes test_len = len(test_features) # print(&quot;testlen&quot;,test_len) for k in range(test_len): class_values = trainy[ind[k,:]] y_true = (testy[k] == class_values) # print(&quot;ylen&quot;,y_true.shape[0]) y_scores = np.arange(y_true.shape[0],0,-1) prec += average_precision_score(y_true, y_scores) for n in range(num_classes): a = class_values[0:(n+1)] counts = np.bincount(a) b = np.where(counts==np.max(counts))[0] if testy[k] in b: acc[n] = acc[n] + (1.0/float(len(b))) prec = prec/float(test_len) acc= [x / float(test_len) for x in acc] del ind,class_values,y_true,y_scores return np.mean(acc)*100,prec def evalknn(self,results): test_features, testy = self.get_features(self.test) train_features, trainy = self.get_features(self.unlabeled) accuracy,mAP = self.calc_mAP(test_features, testy, train_features, trainy) del test_features,testy,train_features,trainy results[args.mode+&#39;_&#39;+str(args.features)+&#39;_&#39;+str(args.labeled)] = [accuracy,mAP] return accuracy,mAP def draw(self, batch_size): self.G.eval() return self.G(batch_size,draw=self.drawnoise).view((batch_size,28,28)).data.cpu().numpy() . . . Pretrain GAN . We&#39;ll first pretrain the GAN for 50 epochs . Original GAN objective . #collapse-hide def pretrain(self): # Reference: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py plotlosses = PlotLosses(groups={&#39;loss&#39;: [&#39;generator&#39;, &#39;discriminator&#39;]}) # Tensor = torch.cuda.FloatTensor if args.cuda else torch.FloatTensor bce_loss = torch.nn.BCELoss() if args.cuda: bce_loss.cuda() dataloader = DataLoader(self.unlabeled, batch_size = args.batch_size, shuffle=True, drop_last=True, num_workers = 4) for epoch in tq(range(args.epochs)): losses = {&#39;discriminator&#39;:0,&#39;generator&#39;:0} for i, (imgs, _) in enumerate(dataloader): valid = torch.ones((imgs.size(0), 1)) fake = torch.zeros((imgs.size(0), 1)) train_imgs = imgs generated_images = self.G(args.batch_size) if args.cuda: valid, fake, train_imgs, generated_images = valid.cuda(), fake.cuda(), train_imgs.cuda(), generated_images.cuda() generator_loss = bce_loss(self.D(generated_images,pretrain=True), valid) self.Goptim.zero_grad() generator_loss.backward() self.Goptim.step() real_loss = bce_loss(self.D(train_imgs,pretrain=True), valid) fake_loss = bce_loss(self.D(generated_images.detach(),pretrain=True), fake) discriminator_loss = (fake_loss + real_loss) / 2 self.Doptim.zero_grad() discriminator_loss.backward() self.Doptim.step() losses[&#39;generator&#39;] += generator_loss.item() losses[&#39;discriminator&#39;] += discriminator_loss.item() num_batches = len(self.unlabeled) / args.batch_size for key in losses: losses[key] /= num_batches plotlosses.update(losses) plotlosses.send() if (epoch + 1) % args.save_interval == 0: torch.save(self.G.state_dict(), self.g_path) torch.save(self.D.state_dict(), self.d_path) ImprovedGAN.pretrain = pretrainargs.load_saved=False args.epochs=50 args.mode = &#39;pretrain&#39; # m=16 n=100 args.labeled=100 args.features=16 gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTLabel(args.labeled/10), MNISTUnlabel(), MNISTTest()) gan.pretrain() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . m=16 . Here we pretrain a model that would generate 16 features given an input image. To generate the images, I created an array with noise and sent it to the generator to get the image. . #collapse-hide args.load_saved=True args.epochs=50 args.mode = &#39;pretrain&#39; # m=16 n=100 args.labeled=100 args.features=16 gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTLabel(args.labeled/10), MNISTUnlabel(), MNISTTest()) gan.pretrain() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . Loss generator (min: 1.549, max: 2.075, cur: 1.775) discriminator (min: 0.391, max: 0.429, cur: 0.409) Done w cdist (30.023548015873082, 0.15303857492111891) . m=32 . #collapse-hide # m=32 n=100 args.features=32 gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTLabel(args.labeled/10), MNISTUnlabel(), MNISTTest()) gan.pretrain() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . Loss generator (min: 1.724, max: 2.207, cur: 1.793) discriminator (min: 0.373, max: 0.414, cur: 0.406) Done w cdist (44.4227202380953, 0.1734273342974863) . Main Training . Improved GAN Objective + Triplet loss . For training the Improved GAN with Triplet loss, I have followed the Improved GAN objective (Salimans et al. 2016) with Triplet Loss in the Discriminator. . #collapse-hide # Reference: https://github.com/Sleepychord/ImprovedGAN-pytorch/blob/master/ImprovedGAN.py def train_Discriminator(self, x1, x2, x3, x_unlabel): output_unlabel, output_fake = self.D(x_unlabel), self.D(self.G(x_unlabel.size()[0]).view(x_unlabel.size()).detach()) loss_supervised = self.tripletloss(self.D(x1), self.D(x2), self.D(x3)) logz_unlabel, logz_fake = log_sum_exp(output_unlabel), log_sum_exp(output_fake) loss_unsupervised = 0.5 * torch.mean(F.softplus(logz_fake)) + 0.5 * -torch.mean(logz_unlabel) + 0.5 * torch.mean(F.softplus(logz_unlabel)) loss = args.unlabel_weight * loss_unsupervised + loss_supervised self.Doptim.zero_grad() loss.backward() self.Doptim.step() return loss_supervised.item(), loss_unsupervised.item() def train_Generator(self, x_unlabel): fake = self.G(args.batch_size).view(x_unlabel.size()) mom_gen = self.D(fake, feature=True).mean(dim=0) mom_unlabel = self.D(x_unlabel, feature=True).mean(dim=0) loss_feature_matching = torch.mean((mom_gen - mom_unlabel).pow(2)) self.Goptim.zero_grad() self.Doptim.zero_grad() loss_feature_matching.backward() self.Goptim.step() return loss_feature_matching.item() def train(self): plotlosses = PlotLosses(groups={&#39;loss&#39;: [&#39;supervised&#39;, &#39;unsupervised&#39;,&#39;generator&#39;]}) for epoch in tq(range(args.epochs)): self.G.train() self.D.train() unlabel_loader1 = DataLoader(self.unlabeled, batch_size = args.batch_size, shuffle=True, drop_last=True, num_workers = 4) unlabel_loader2 = DataLoader(self.unlabeled, batch_size = args.batch_size, shuffle=True, drop_last=True, num_workers = 4).__iter__() label_loader = DataLoader(self.labeled, batch_size = args.batch_size, shuffle=True, drop_last=True, num_workers = 4).__iter__() # loss_supervised = loss_unsupervised = loss_generator = 0. losses = {&#39;supervised&#39;:0,&#39;unsupervised&#39;:0,&#39;generator&#39;:0} for (unlabel1, _) in unlabel_loader1: unlabel2, _ = unlabel_loader2.next() x1,x2,x3 = label_loader.next() if args.cuda: x1, x2, x3, unlabel1, unlabel2 = x1.cuda(), x2.cuda(), x3.cuda(), unlabel1.cuda(), unlabel2.cuda() l_supervised, l_unsupervised = self.train_Discriminator(x1, x2, x3, unlabel1) losses[&#39;unsupervised&#39;] += l_unsupervised losses[&#39;supervised&#39;] += l_supervised generator_loss = self.train_Generator(unlabel2) if epoch &gt; 1 and generator_loss &gt; 1: generator_loss = self.train_Generator(unlabel2) losses[&#39;generator&#39;] += generator_loss batch_num = len(self.unlabeled) // args.batch_size for key in losses: losses[key] /= batch_num plotlosses.update(losses) plotlosses.send() if (epoch + 1) % args.save_interval == 0: torch.save(self.D.state_dict(), self.d_path) torch.save(self.G.state_dict(), self.g_path) ImprovedGAN.train = train ImprovedGAN.train_Discriminator = train_Discriminator ImprovedGAN.train_Generator = train_Generator . . Triplet Loss and M=16 N=100 . Here M is the number of features generated by the discriminator and N is the number of samples on which we did supervised training, on rest of the samples we do unsupervised training. . #collapse-hide %%time args.load_saved=True args.epochs=70 args.labeled=100 args.features=16 args.mode = &#39;train&#39; gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTTriplet(MNISTLabel(args.labeled/10)), MNISTUnlabel(), MNISTTest()) gan.train() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . Loss supervised (min: 0.000, max: 0.079, cur: 0.000) unsupervised (min: 0.351, max: 0.453, cur: 0.422) generator (min: 0.511, max: 1.353, cur: 0.511) Done argsort (96.17309999999998, 0.9155653700006265) CPU times: user 53min, sys: 2min 10s, total: 55min 11s Wall time: 1h 5min 43s . Triplet Loss and M=16 N=200 . #collapse-hide args.load_saved=True args.epochs=70 args.labeled=200 args.features=16 gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTTriplet(MNISTLabel(args.labeled/10)), MNISTUnlabel(), MNISTTest()) gan.train() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . Loss supervised (min: 0.000, max: 0.106, cur: 0.000) unsupervised (min: 0.368, max: 0.463, cur: 0.413) generator (min: 0.487, max: 1.185, cur: 0.487) Done argsort (96.44481666666665, 0.931573062438397) . Triplet Loss and M=32 N=100 . #collapse-hide args.load_saved=True args.epochs=70 args.labeled=100 args.features=32 gan = ImprovedGAN(Generator(z_dim=100), Discriminator(output_dim=args.features), MNISTTriplet(MNISTLabel(args.labeled/10)), MNISTUnlabel(), MNISTTest()) gan.train() # gan.trainknn() print(gan.evalknn(results)) show_gen_images(gan) . . Loss supervised (min: 0.000, max: 0.098, cur: 0.000) unsupervised (min: 0.355, max: 0.485, cur: 0.430) generator (min: 0.680, max: 2.149, cur: 0.699) Done argsort (95.97931666666668, 0.9031129058147167) . Results . #collapse-hide from tabulate import tabulate results = [[16, 100, 96.17309999999998, 0.9155653700006265], [16, 200, 96.44481666666665, 0.931573062438397], [32, 100, 95.97931666666668, 0.9031129058147167]] print(tabulate(results,headers=[&#39;Features&#39;,&#39;Supervised samples&#39;,&#39;Accuracy&#39;,&#39;mAP&#39;])) . . Features Supervised samples Accuracy mAP - -- - -- 16 100 96.1731 0.915565 16 200 96.4448 0.931573 32 100 95.9793 0.903113 .",
            "url": "https://rohanrajpal.com/deep-learning/2020/06/30/GAN-Triplet.html",
            "relUrl": "/deep-learning/2020/06/30/GAN-Triplet.html",
            "date": " • Jun 30, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data",
            "content": "Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. . Deep Learning has had phenomenal success in computer vision tasks. However, one requires a large amount of labelled data to extract good enough representations. That is why its challenging to use Deep Learning with a short amount of labelled data. However, there has been recent research using unsupervised methods to develop representations of data. . Till date, the methods in unsupervised representation learning try to Auto Encode Data (AED). This paper explores the dynamics of feature representations under different transformations by Auto Encoding Transformations (AET) instead of data. They realise that as long as an unsupervised model learns sufficiently informative representations of the original and the transformed image, a model can decode the transformation. . . They present an AET paradigm which allows us to instantiate a wide range of operators which include parameterised, non-parameterized and GAN-induced transformations. AET achieves state-of-the-art performances on Imagenet, CIFAR-10 and Places dataset. Additionally, its results demonstrate an accuracy close to the cap set by its supervised counterparts. Further analysis of AET loss with accuracy and error plots reveals predictions of transformations are a good indicator for better classification results. . In their method, they predict the transformation from the representations of the original and transformed image. To predict parametric transformations, they use a loss function based on the difference of the parameters of the transformation. For GAN-Induced transformations, they calculate the difference between the noise parameters for the loss function. Finally, for non-parametric transformations, they measure the average distance between the transformations and the randomly sampled images. . To evaluate the model, they build a classifier on top of the architecture they use for a dataset. They test their model on the CIFAR-10, Imagenet and the Places dataset. In the CIFAR-10 experiment, they adopt a Network in Network (NIN) architecture which they train by SGD with a composition of transformations. For classification, they use a model-based and a model-free classifier. For the model-based classifier, they build a non-linear classifier with three FC layers. The model-free classifier is a KNN classifier based on the average pooled features from the second convolutional block. The AET outperforms all the other unsupervised methods. Additionally, with the convolutional classifier, AET performs almost similar to fully supervised NIN architecture. However, a direct comparison between AET and other experiments is difficult, as other methods have different architectures and hyperparameters. In the Imagenet dataset, they take two AlexNet branches with its 1000-way linear classifier. They achieve the best results among the other unsupervised models. In the places dataset, they assess the generalisability of their representations by using the previous architecture pretrained on Imagenet. They achieve the best results except in a few scenarios. . Although AET gets impressive results, the motivation to encode transformations instead of data isn’t clear and scattered throughout the paper. Also, all of their results are based on parametric transformations because they couldn’t get as good results with other operators. However, they couldn’t concretise on why other transformations didn’t work well. The paper presents an excellent motivation to improve unsupervised methods of learning. They explain their methods and evaluations in-detail and use ablations to find out the exact reasons. Along with the advantages, they also highlight the drawbacks of their approach, providing a balanced view. However, it was hard to understand the motivation to learn transformations instead of data. Bringing together the motivation for transformations in the introduction would have explained their approach better. .",
            "url": "https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html",
            "relUrl": "/paper%20summary/2020/06/28/dl-aet-vs-aed.html",
            "date": " • Jun 28, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Deep Learning cheat sheet for Python",
            "content": "Having worked on Deep Learning for almost a year, I kept noting useful resources and snippets I used frequently. I&#39;ve compiled all of them in one place below. Feel free to share some of your hacks/resources/snippets below. Leave a comment below, pull requests are welcome too! . . Jupyter clear GPU Memory . There are times I just cant afford to restart the kernel lol. The snipped below helps me in those cases . # collapse-hide import gc def dump_tensors(gpu_only=True): torch.cuda.empty_cache() total_size = 0 for obj in gc.get_objects(): # print(obj) try: if torch.is_tensor(obj): if obj.is_cuda: del obj gc.collect() elif hasattr(obj, &quot;data&quot;) and torch.is_tensor(obj.data): if not gpu_only or obj.is_cuda: del obj gc.collect() except Exception as e: pass dump_tensors() . . Free Quality Courses . Machine Learning Taught by a professor in Cornell, love his style of teaching | . | Deep Learning Fastai | Deep Learning for Visual Recognition | Variational Autoencoder | . Free GPU resources . Resources below are mostly student focussed . a good list of free resources | free Azure,AWS and MongoDB creds (Student Developer Pack) | google cloud resources | . Computer Vision models . PyTorch Image Models | fastai | (Generic) EfficientNets for PyTorch | EfficientNet PyTorch | . GANs . Improved GAN (Semi-supervised GAN) | Pytorch GAN | . Training tools . tqdm: A progressbar | livelossplot best way to analyse plots while training | . | The most lightweight experiment management tool that fits any workflow | fastpages | . Pre/Post processing . Train-val split pytorch | Augmix | Cutmix | Quick test time augmentation | librosa: Audio extraction | . K Fold Cross Validation . # collapse-hide num_splits = 5 all_probs = torch.zeros(610, 3, dtype=torch.float32) # for i in range(2,2+1): train_dataset, valid_dataset = get_train_valid_dataset(PROJECT_PATH + &quot;data/train/&quot;,batch_size=batch_size,augment=True, random_seed=42,valid_size=0.2,shuffle=True,show_sample=False, num_workers=4,pin_memory=True,split_no=1) skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) # https://discuss.pytorch.org/t/how-can-i-use-sklearn-kfold-with-imagefolder/36577 # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold pin_memory=True for fold_num, (train_index, test_index) in enumerate(tq(skf.split(train_dataset, train_dataset.targets))): # valid_subset = torch.utils.data.Subset(valid_dataset,test_index) train_sampler = ImbalancedDatasetSampler(train_dataset,train_index) valid_sampler = ImbalancedDatasetSampler(valid_dataset,test_index) train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers, pin_memory=pin_memory ) valid_loader = torch.utils.data.DataLoader( valid_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers, pin_memory=pin_memory ) model_name = &#39;densenet201&#39; optim_name = &#39;AdamW&#39; lr = 8e-5 PARAMS = {&#39;learning_rate&#39; : lr, &#39;n_epochs&#39; : 40, &#39;optimizer&#39; : optim_name, &#39;model&#39; : model_name, &#39;fold&#39; : fold_num, &#39;save_name&#39;: model_name+&#39;_TTA_&#39;+optim_name+&#39;_fold_&#39;+str(fold_num)+&quot;_img_&quot;+str(img_size)+&#39;_lr-&#39;+str(lr) } neptune.create_experiment(name=&#39;pytorch-&#39;+model_name+&#39;-Adam&#39;, params=PARAMS) print(&quot;Started train for fold&quot;,fold_num) model = trainCNN(PARAMS[&#39;n_epochs&#39;],train_loader,valid_loader,model_name,True, PARAMS[&#39;save_name&#39;],PARAMS[&#39;learning_rate&#39;],False) preds_path,preds_prob = predict(test_loader, model,True) make_submission(preds_prob,preds_path,PARAMS[&#39;save_name&#39;]) all_probs+= preds_prob . . Cyclic loaders . The standard loader from itertools takes a lot of RAM. The piece of code below reduced my RAM usage by 5 times. Thanks to rmrao for the solution. . # collapse-hide def cycle(iterable): iterator = iter(iterable) while True: try: yield next(iterator) except StopIteration: iterator = iter(iterable) . . Reproducibility . Quick function to set all the seeds of Pytorch . # collapse-hide # seeding function for reproducibility def seed_everything(seed): random.seed(seed) os.environ[&quot;PYTHONHASHSEED&quot;] = str(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.backends.cudnn.deterministic = True . .",
            "url": "https://rohanrajpal.com/deep-learning/2020/06/25/deep-learning-cheat-sheet.html",
            "relUrl": "/deep-learning/2020/06/25/deep-learning-cheat-sheet.html",
            "date": " • Jun 25, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Paper Summary: Triboelectric nanogenerators as new energy technology and self-powered sensors – Principles, problems and perspectives",
            "content": "Wang, Z.L. 2014. Triboelectric nanogenerators as new energy technology and self-powered sensors – Principles, problems, and perspectives. Faraday Discuss. 176, (2014), 447–458. . This paper aims to review and give updated progress of Triboelectric Nanogenerators or TENG. The TENG is based on the principle of triboelectrification and electrostatic induction. This article also discusses its applications as a new energy generation technology and self-powered active sensors. There has been a boom in mobile computing devices in recent decades. To power these billions of devices, we require billions of batteries. However, the battery has a limited lifetime, and replacing the batteries of billions of gadgets is a humongous task. The direction of portable electronics is towards low power consumption; this makes it possible to harvest energy from the environment around the device. A newly emerging field of nano energy is to create independent nanotech-based power sources. They can harness energy from micro-scale like daily activities to macro-scale like ocean waves. The article also discusses TENG as self-powered sensors. . . The author lays down four fundamental modes of triboelectric nanogenerators. There is vertical contact, lateral sliding, single-electrode, and freestanding triboelectric-layer. With these primary modes, TENGs are explored as both a micro and macro source for power generation. Micro here refers to powering small and mobile gadgets. Macro refers to large-scale energy generation. This article explores the contact electrification between a solid and liquid surface for macro purposes. With these modes and applications, some fundamental problems with triboelectric are discussed as well. First, more clarity is needed on the underlying mechanism of the triboelectric effect. The effect has to be investigated much more in-depth to understand its working better. This article also found a way to quantify the performance of TENG’s based on different modes. This article used a measurement matrix to quantify the performance. Finding the right pair of materials to generate the best output is also a problem to solve. One might say the triboelectric series is helpful, but there is no quantitative measure to compare how much energy two materials in a TENG can generate. External factors like humidity have a significant impact on triboelectricity. This means the TENG should have packaging to protect itself from outdoor conditions. Many more such problems are discussed. . As this paper is relatively recent, most of the applications are yet to be implemented. However, I firmly believe this technology can have a significant impact on wearables. This article mostly covers the generation before wearables, mobile devices. With wearables, we are moving towards even more portable, smaller, and less power-consuming devices. All of these aspects support the use of TENGs. With the evolution of low powered light devices like LEDs, TENGs might even bring light to thousands of homes across the world, which still don’t have full-time access to electricity. .",
            "url": "https://rohanrajpal.com/paper%20summary/2020/06/20/triboelectric-nanogenerators.html",
            "relUrl": "/paper%20summary/2020/06/20/triboelectric-nanogenerators.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Paper Summary: Toward Silent-Speech Control of Consumer Wearables",
            "content": "Bedri, A., Sahni, H., Thukral, P., Starner, T., Byrd, D., Presti, P., Reyes, G., Ghovanloo, M. and Guo, Z., 2015. Toward silent-speech control of consumer wearables. Computer, 48(10), pp.54-62. . Not being able to speak because of conditions like dysarthria and aphonia can be substantial communication barriers. People with such conditions can use Augmentative and Alternative Communication (AAC) systems, but such systems are much slower than speech. For a person with good mouth articulation, silent speech systems can be a much faster way to communicate. Silent speech can be extended for places with high noise, like firefighters, public transport, combat soldiers. It can also be used the other way around, like jaw gestures for acknowledging a message in stealth environments. The authors realised a vital requirement for silent systems. Such systems have to be unobtrusive. The aim is to make a system that is indistinguishable from devices like earphones. . The authors first explored the feasibility of the already existing TDS(Tongue Driven System). They achieved 96 per cent accuracy on the test and realised it is possible to work on such systems. Inspired from these interfaces, the authors came up with Tongue-Magnet-Interface (TMI) and Outer-Ear-Interface (OEI). TMI detects tongue movements using google glass with a magnet placed on the tongue. OEI detects jaw movements and can be installed in any ordinary headphone. The researchers tried to conduct various experiments with the TMI and OEI. In the first experiment, they used TMI and OEI together, and they achieved an average user-dependent recognition accuracy of 90 per cent. They then considered experimenting with the OEI alone, as that would eliminate tongue piercing. With the OEI alone they realised that TMI and OEI did not recognise the same phrases, realising they need to design the phrases more carefully. Then they experimented with improved OEI and Simple jaw gestures in which they achieved 84 per cent overall classification accuracy, user-dependent results had even better results with 97 per cent accuracy. The experiments were helping them in constructing the phrases and well as the design of the wearable. In the last investigation, they explore how heart rate can be used to calibrate the sensors for better performance. . With the evolution of Deep Learning in the previous five years, one can now use Deep Learning models for the same tasks. It might help in improving accuracy and maybe even help us in noticing some exciting features of the data we get from the sensors. The authors conducted the study of OEI with only a single subject. They concluded that there is a need to carefully design the phrases which will be used for silent speech recognition as OEI and TMI recognises them differently. So a study with more subjects and the improved OEI system can be conducted to determine how these phrases are needed to be designed to help the practitioners who are actually going to use this research and implement it into a solution. .",
            "url": "https://rohanrajpal.com/paper%20summary/2020/06/20/silent-speech-wearables.html",
            "relUrl": "/paper%20summary/2020/06/20/silent-speech-wearables.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Paper Summary: Don’t Mind Me Touching My Wrist: A Case Study of Interacting with On-Body Technology in Public",
            "content": "Halley P. Profita, James Clawson, Scott Gilliland, Clint Zeagler, Thad Starner, Jim Budd, and Ellen Yi-Luen Do. 2013. Don’t mind me touching my wrist: a case study of interacting with on-body technology in public. In Proceedings of the 2013 International Symposium on Wearable Computers (ISWC ’13). . This paper aims to study body interactions in the Public. Wearable tech, especially E-textile, introduces new kinds of on-body interactions. These interactions, however, are nontraditional. People might even find them uncomfortable to perform relative to time or place. These interactions might also be awkward for someone’s culture. . The authors aimed to answer these concerns by performing a survey-based study. The study involved two actors interacting with each other in a lift. One of the actors would be donning a wearable e-textile, who would receive a call and would reject it through the wearable. The third-party participant would view a video of this scene. The researchers conducted this study in the US and South Korea. The wearable e-textile used in this study was a jog wheel. They considered six different positions for the jog-wheel: collarbone, torso, waist, forearm, wrist and pocket. In each video, the actor would wear this textile in one of the six places. For a baseline, they also recorded videos of participants rejecting the call through their blackberry. After viewing the videos, the participant would answer eleven Likert scale questions from “Strongly Agree” to “Strongly Disagree” on the wearable placement. The researchers asked some additional attitudinal questions on the perception and position of the e-textile. Finally, participants would answer a follow-up questionnaire; they provided open-ended responses to the two most and two least preferred locations. In the results, the US and Korea resembled at some places. There were gender differences with respect to wearable placement and interactions. Interactions were less socially acceptable around the male’s waist area and on the waist and upper body areas of women. The wrist and the forearm came out to be the two most common on-body places for both countries, probably because they are the most common places for a wearable. However, the authors did succeed in finding the differences across cultures. For Americans, the most common concern was accidental triggering, while it was the interface for Koreans. In the follow-up questionnaire, Americans preferred a system that was easy to operate, whereas only 6.9 per cent of Koreans felt the same. South Koreans preferred a system that avoided making the user look weird or awkward. . There are many avenues we can explore with the help of this study. For example, the lift had opposite genders interacting, one can view the differences if both the characters of the lift are of the same gender. As the focus of the study is to study interactions in public, situations with more than two characters might also bring new insights. .",
            "url": "https://rohanrajpal.com/paper%20summary/2020/06/20/on-body-interactions.html",
            "relUrl": "/paper%20summary/2020/06/20/on-body-interactions.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Competitive Programming: C++ Cheat Sheet",
            "content": "Syntax and tricks for C++. . Improve speed . Leetcode . static int fastio = []() { ios::sync_with_stdio(false); cin.tie(NULL); cout.tie(0); return 0; }(); . Normal compile . #define fast ios_base::sync_with_stdio(false),cin.tie(NULL) . Header Template . #include&lt;bits/stdc++.h&gt; #define ll long long #define ld long double #define vll vector&lt;ll&gt; #define vii vector&lt;int&gt; #define vvll vector&lt; vll &gt; #define pll pair&lt;ll ,ll &gt; #define MOD 1000000007 #define rall(v) v.rbegin(),v.rend() #define fst first #define mp make_pair #define pb push_back #define fast ios_base::sync_with_stdio(false),cin.tie(NULL) #define int long long #define endl &quot; n&quot; #define all(v) v.begin(),v.end() #define scd second #define for1(i,n) for(ll (i) = 1 ; (i) &lt;= (n) ; ++(i)) #define forr(i,n) for(ll (i) = (n)-1 ; (i)&gt;=0 ; --(i)) #define forn(i,n) for(ll (i) = 0 ; (i) &lt; (n) ; ++(i)) #define forab(i,a,b,c) for(ll (i) = a ; (i) &lt;= (b) ; (i)+=(c)) #define mst(A) memset( (A) , 0 , sizeof(A) ); #define tc() int t; cin &gt;&gt; t ; while (t--) using namespace std; . Comparators . class Solution { public: int twoCitySchedCost(vector&lt;vector&lt;int&gt;&gt;&amp; costs) { sort(costs.begin(),costs.end(),[](auto &amp;i1,auto &amp;i2) -&gt; bool {return i1[0] - i1[1] &lt; i2[0] - i2[1];}); int sum=0; for(int i=0;i&lt;costs.size()/2;i++){ sum += costs[i][0] + costs[costs.size()-1-i][1]; } return sum; } }; . Pointers and Addresses . A pointer stores a memory address. . Some ways to do the same thing . ListNode *root=new ListNode(),*node=root; ListNode root,*node=&amp;root; //node is the same above . Hashmap . Map of pairs . struct hash_pair { template &lt;class T1, class T2&gt; size_t operator()(const pair&lt;T1, T2&gt;&amp; p) const { auto hash1 = hash&lt;T1&gt;{}(p.first); auto hash2 = hash&lt;T2&gt;{}(p.second); return hash1 ^ hash2; } }; unordered_map&lt;pair&lt;int, int&gt;, bool, hash_pair&gt; um; . Increase map speed . umap.reserve(n) . String stuff . int to string . class Solution { public: vector&lt;string&gt; fizzBuzz(int n) { vector&lt;string&gt; ans(n); for(int i=1;i&lt;=n;i++){ if(i%3==0 and i%5==0) ans[i-1]=&quot;FizzBuzz&quot;; else if(i%3==0) ans[i-1]=&quot;Fizz&quot;; else if(i%5==0) ans[i-1]=&quot;Buzz&quot;; else ans[i-1]=to_string(i); } return ans; } }; . Priority Queue . //max heap priority_queue &lt;int&gt; g = gq; //min heap priority_queue &lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; gquiz; .",
            "url": "https://rohanrajpal.com/competitive%20programming/2020/06/20/cpp-cheat-sheet.html",
            "relUrl": "/competitive%20programming/2020/06/20/cpp-cheat-sheet.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "DSA Interview Prep Resources",
            "content": "In this blog I’ll document some resources and all the challenging competitive programming problems with the focus on motivation rather than the solution. . 5 Problem Solving Tips for Cracking Coding Interview Questions . Youtube] Tip #1: Come up with a brute-force solution - Tip #2: Think of a simpler version of the problem - Tip #3: Think with simpler examples -&gt; try noticing a pattern - Tip #4: Use some visualization - Tip #5: Test your solution on a few examples - . Study Plan . Leetcode top interview questions Generic preparation tips I give to freshers to clear any algorithmic interview anywhere: . 1) Data Structures and Algorithms (online course on NPTEL by Naveen Garg) 2) Analysis and Design of Algorithms (online course on Coursera by Tim Roughgarden, part 1 and part 2 3) 1 programming language, everything about it including inbuilt things like maps, binary search, sort, stacks, priority queues, vectors / lists, pairs etc 4) all Codeforces contests from now till interviews 5) 200+ Leetcode questions . Take the competitive programming course if you haven’t done that already. . Best of the best blogs . Yash girdhar Good plan of how to prepare | . | Abinav Bhardwaj Screenshots of contests of various company contests | . | Resources by google | Five Essential Phone Screen Questions by Steve Yegge | How to: Work at Google — Candidate Coaching Session for Technical Interviewing | How To Get Hired – What CS Students Need to Know | Topcoder tutorials | . TLE reasons . does not satisfy constraints | infinite loop in code | created an endless linked list and returned it | . Array . Remove Duplicates from Sorted Array . Leetcode . The question is interesting because you have to ensure the array is modified, too, not just return the answer. . class Solution { public: int removeDuplicates(vector&lt;int&gt;&amp; nums) { int j=!nums.empty(); for(int i=1;i&lt;nums.size();i++){ if(nums[i]&gt;nums[j-1]){ nums[j++]=nums[i]; } } return j; } }; . 3Sum . Leet link . class Solution { public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) { vector&lt;vector&lt;int&gt;&gt; ans; sort(nums.begin(),nums.end()); for(int i=0;i&lt;nums.size();i++){ int front=i+1,back=nums.size()-1,target=-nums[i]; // cout&lt;&lt;&quot;in n&quot;; while(front&lt;back){ // cout&lt;&lt;front&lt;&lt;&quot; &quot;&lt;&lt;back&lt;&lt;&quot; n&quot;; int sum = nums[front]+nums[back]; if(sum&lt;target) front++; else if(sum&gt;target) back--; else{ // cout&lt;&lt;&quot;ansadd n&quot;; vector&lt;int&gt; elem = {nums[i],nums[front],nums[back]}; ans.push_back(elem); front++; back--; //find duplicates of idx 1 while(front&lt;back and nums[front] == nums[front-1]) front++; //find duplicates of idx 2 while(front&lt;back and nums[back] == nums[back+1]) back--; } } while(i+1 &lt; nums.size() and nums[i]==nums[i+1]) i++; } return ans; } }; . Set Matrix Zeroes . Leetcode Solution | Solution | . Brute approach: Just store an alternative matrix that would store whether the i,j element should be zero or not. This is O(mxn) space solution. . Brute space efficient approach: For each arr[i][j] which is zero, go through the row and column and mark it zero with a flag. Might not work if the constraints are full integer. . O(m+n) approach: Have some state array for row and column, which tells whether i and j is 0. . O(1) approach: We have though of the O(m+n) approach, how about we just store those states in the 2d array itself? . class Solution { public: void setZeroes(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { int m=matrix.size(),n=matrix[0].size(),col=1; for(int i=0;i&lt;m;i++){ if(matrix[i][0]==0) col=0; for(int j=1;j&lt;n;j++) if(matrix[i][j]==0) matrix[0][j] = matrix[i][0] = 0; } for(int i=m-1;i&gt;=0;i--){ for(int j=n-1;j&gt;=1;j--) if(matrix[0][j]==0 or matrix[i][0]==0) matrix[i][j]=0; if(col==0) matrix[i][0]=0; } } }; . Dynamic Programming . A smart brute force and your algorithm goes from cubic to linear complexity. That’s dynamic programming. . Coin Change 2 . Leetcode . We can use a coin infinite number of times, but how many times do we need? We know that the amounts a coin can make, so why not just store the count of the amount that we have made? Out of all the possible amount, if you add that value to . Say we have used a part of the array to build our answer, now we come across a new coin: For a coin of value c, if previously we had n number of ways to make vaulue i-c, in how many ways can we make i? ways[i-c] + already existing ways to make i. . class Solution { public: int change(int amount, vector&lt;int&gt;&amp; coins) { vector&lt;int&gt; dp(amount+1); dp[0] =1; for(auto&amp; coin: coins){ for(int i=coin;i&lt;=amount;i++) dp[i] += dp[i-coin]; } return dp[amount]; } }; . Dungeon Game . Leetcode Mistakes I made: please dry run before coding . Notice that the minimum initial health will be at least 1 even if we have an example like [1,0,0]. . When we reach the queen, say value in that cell is -3, so we must have 1-(-2) health to save the queen. The minimum initial length at the bottom right should be max(1,1-dungeon[i][j]). . Now at any i,j, if we need 3 points of health for future, we will add requirements of health for current i,j, so health will be 3 - (-4). We should have max(1,min(dp[i+1][j],dp[i][j+1])-dungeon[i][j]) health. . Top down DP (Easier to understand) . class Solution { public: int m,n; int calculateMinimumHP(vector&lt;vector&lt;int&gt;&gt;&amp; dungeon) { m = dungeon.size();n=dungeon[0].size(); vector&lt;vector&lt;int&gt;&gt; dp(m,vector&lt;int&gt;(n,0)); return calcMin(dungeon,dp,0,0); } int calcMin(vector&lt;vector&lt;int&gt;&gt;&amp; dungeon, vector&lt;vector&lt;int&gt;&gt;&amp; dp, int i, int j){ if(i&gt;=m or j&gt;=n) return INT_MAX; if(i==m-1 and j==n-1) return max(1,1 - dungeon[i][j]); if(dp[i][j]) return dp[i][j]; return dp[i][j] = max(1,min(calcMin(dungeon,dp,i,j+1),calcMin(dungeon,dp,i+1,j)) - dungeon[i][j]); } }; . Bottom up DP (Space optimized) We dont really need to make an extra array when doing bottom up. . class Solution { public: int calculateMinimumHP(vector&lt;vector&lt;int&gt;&gt;&amp; dungeon) { int m=dungeon.size(),n=dungeon[0].size(); for(int i=m-1;i&gt;=0;i--) for(int j=n-1;j&gt;=0;j--) if(i==m-1 and j==n-1) dungeon[i][j] = max(1,1-dungeon[i][j]); else if(i==m-1) dungeon[i][j] = max(1,dungeon[i][j+1]-dungeon[i][j]); else if(j==n-1) dungeon[i][j] = max(1,dungeon[i+1][j]-dungeon[i][j]); else dungeon[i][j] = max(1,min(dungeon[i][j+1],dungeon[i+1][j])-dungeon[i][j]); return dungeon[0][0]; } }; . Distinct Subsequences . Leetcode Questions . Strings . Longest Substring Without Repeating Characters . Leetcode link Redundant step: no need to clear previous dictionary values, just update the start . class Solution { public: int lengthOfLongestSubstring(string s) { int start=-1,maxlen=0; unordered_map&lt;char,int&gt; umap; for(int i=0;i&lt;s.size();i++){ if(umap.count(s[i])!=0){ start=max(start,umap[s[i]]); } umap[s[i]]=i; if(maxlen&lt;i-start) maxlen=i-start; } return maxlen; } }; . Maths . Permutation Sequence . Leetcode | Solution Reference | . C++ has an inbuilt function next_permuation . class Solution { public: string getPermutation(int n, int k) { string seq=&quot;&quot;; for(int i=1;i&lt;=n;i++) seq+=(&#39;1&#39;+i-1); while(--k&gt;0) next_permutation(seq.begin(),seq.end()); return seq; } }; . Complexity: O(k) . Can we do better? Absolutely! Let’s take n=4; the permutations will be . 1 - (2,3,4) (2,4,3) ... 2 - (1,4,3) ... 3 - (1,2,4) ... 4 - (1,2,3) ... . On removing the first index, the rest of the permutations are repeating. If we want to find the 22nd permutation. The first index will be k/(n-1)! = 21 / (4-1)! = 21 / 3! = 3. 3rd index of [1,2,3,4] is 4. So the first number would be 4. The permutation till here is “4” Now how do we find the index in the remaining combinations? Before the index, we have covered index*(n-1)! permutations. Subtracting this from k will give us the index for the new sub problem k = k % (n-1) = 21 % (4-1)! = 21 - 18 = 3 We also remove 4 from the set now. Set is now . 1 - (2,3) (3,2) 2 - (3,1) ... 3 - (1,2) (2,1) . index = 3 / (n-2)! = 3 / 2! = 1 Now the index at 1 in [1, 2, 3] is 2. Permutation now is “42” Left out set is [1 , 3] k = 3 % 2! = 1 index = 1 / 1! = 1. Elem at 1 is 3, permutation is “423” Finally, k = 1 - 1*0! = 0 Adding the left-out element perm is finally = “4231” . class Solution { public: string getPermutation(int n, int k) { string seq=&quot;&quot;;k--; vector&lt;int&gt; nums,fact(n+1,1); for(int i=1;i&lt;=n;i++) nums.push_back(i); for(int i=1;i&lt;=n;i++) fact[i] = fact[i-1]*i; for(;n&gt;0;n--){ int idx = k / fact[n-1]; seq += (nums[idx]-1) + &#39;1&#39;; k %= fact[n-1]; nums.erase(nums.begin()+idx); } return seq; } }; . Number of 1 Bits . Leetcode link A nice trick to avoid going through zeros as well. . class Solution { public: int hammingWeight(uint32_t n) { int count=0; while(n){ count+=1; n=n&amp;(n-1); } return count; } }; . Graphs . Cheapest Flights Within K Stops (Dijkstra) . We can take the Dijkstra algorithm and modify it so that distances greater than k hops will not be considered. . #define INF 0x3f3f3f3f class Point { public: int node; int dist; int hops; Point(int a, int b, int c){ node=a;dist=b;hops=c; } }; class myComparator { public: int operator() (const Point&amp; p1, const Point&amp; p2) { return p1.dist &gt; p2.dist; } }; class Solution { public: int findCheapestPrice(int n, vector&lt;vector&lt;int&gt;&gt;&amp; flights, int src, int dst, int K) { if(flights.size()==0 or n==0) return -1; vector&lt;vector&lt;pair&lt;int,int&gt;&gt;&gt; adj(n,vector&lt;pair&lt;int,int&gt;&gt;(0)); for(int i=0;i&lt;flights.size();i++){ adj[flights[i][0]].push_back(make_pair(flights[i][1],flights[i][2])); } priority_queue &lt;Point, vector&lt;Point&gt;, myComparator&gt; pq; pq.push(Point(src,0,0)); vector&lt;int&gt; dist(n,INF); dist[src]=0; while(!pq.empty()){ Point cur = pq.top(); pq.pop(); if(cur.node == dst) return cur.dist; if(cur.hops &gt; K) continue; for(int i=0;i&lt;adj[cur.node].size();i++) if(dist[adj[cur.node][i].first] &gt; cur.dist+adj[cur.node][i].second) pq.push(Point(adj[cur.node][i].first,cur.dist+adj[cur.node][i].second,cur.hops+1)); } return -1; } }; . Tree . Count Complete Tree Nodes . Leetcode link . class Solution { public: int countNodes(TreeNode* root) { int height = findHeight(root); return height&lt; 0? 0: findHeight(root-&gt;right)==height-1? (1&lt;&lt;height) + countNodes(root-&gt;right):(1&lt;&lt;(height-1)) + countNodes(root-&gt;left); } int findHeight(TreeNode* node){ return node==NULL?-1 : 1+findHeight(node-&gt;left); } }; . Binary Search . Longest Duplicate Substring (Rolling Hashes) . Leetcode link . Do a binary search on length Have the least length as 0 and highest as n-1 | Take the mid-length, if you find a duplicate, try for a bigger length | If not, try for a smaller length | . | Sliding window (Robin Karp) Have a look at the rolling hash approach | . | robin karp solution | c++ 17 solution | . Backtracking . The way I think of backtracking is as follows: 1. Make a change 2. Recurse 3. Undo the change If at any point we reach the goal state, return true/print/whatever. - So for the sudoku problem: For all possible squares on the board see if we can add any value between 1-9. If we can, add the value and recurse for the rest of the board. Then undo the changes by making the board blank again. Goal state is when we have successfully filled in last square - For n queens: Iterate through the first row. If we can place a queen at a given column place it and recurse for the remaining rows. Then undo the change by removing the queen and moving to the next column. Goal is when we have placed queen on nth row - Print all possible permutations: Initialize an empty String for results. In the input string iterate through each character. For each character, remove it from input and add it to result and recurse. Then remove the character from result and insert it back in same position in input string. Goal is when result size = n. - Given n print all sets of valid parentheses that amount to n: Start with blank input string and 2 numbers i, j initialized to n that denote number of opening/closing parentheses remaining - you can add opening parentheses to the string if i&gt;0. You can add closing parentheses if j&gt;i. If you can add opening parentheses, add it to stringbuilder, recurse and then remove it from end of stringbuilder. If you can add closing parentheses add it to stringbuilder, recurse and then remove it from end of stringbuilder. Goal is when both i, j =0. - Print all subsets of a set: For each character in set, remove it from input set add it to result set and if it has not been printed already, print (goal is any set that has not been printed already). Then recurse for remaining elements. Then remove element from result set and add it back to input set. Pretty much all the backtracking problems I have done follows this pattern. . Letter Combinations of a Phone Number . Leetcode link . class Solution { public: vector&lt;string&gt; nmap = {&quot;&quot;,&quot;&quot;,&quot;abc&quot;,&quot;def&quot;,&quot;ghi&quot;,&quot;jkl&quot;,&quot;mno&quot;,&quot;pqrs&quot;,&quot;tuv&quot;,&quot;wxyz&quot;}; vector&lt;string&gt; ans; vector&lt;string&gt; letterCombinations(string digits) { if(digits.size()==0) return ans; makeComb(digits,0,&quot;&quot;); return ans; } void makeComb(string&amp; digits, int i, string comb){ if(i==digits.size()) { ans.push_back(comb); return; } for(char ch:nmap[digits[i]-&#39;0&#39;]) makeComb(digits,i+1,comb+ch); } }; . Generate Parentheses . Leetcode link . What would be a brute force solution here? Try all 2^n combinations and check if they are valid or not. . A better way would be to instead construct only those parentheses which are valid. Now when is a parentheses valid? When we have more ‘(‘ than ‘).’ So lets construct from the left and only add ‘)’ when their number is less than ‘(‘ . Bonus: change the string you’re making in place to save space and time. . class Solution { public: vector&lt;string&gt; generateParenthesis(int n) { int m=n; vector&lt;string&gt; res; string s=&quot;&quot;; genP(n,0,0,res,s); return res; } void genP(int n, int open, int close, vector&lt;string&gt; &amp;res, string &amp;s){ if(open==n and close==n) { res.push_back(s); return; } s.push_back(&#39;(&#39;); if(open&lt;n) genP(n,open+1,close,res,s); s.pop_back(); s.push_back(&#39;)&#39;); if(close&lt;open) genP(n,open,close+1,res,s); s.pop_back(); } }; . Linked List . Add two Numbers . Make a new linked list and store the results into that. . class Solution { public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { int c=0; ListNode *root=new ListNode(),*node=root; while(l1 || l2 || c){ if(l1) c+=l1-&gt;val,l1=l1-&gt;next; if(l2) c+=l2-&gt;val,l2=l2-&gt;next; node-&gt;next = new ListNode(c%10); c /= 10; node = node-&gt;next; } return root-&gt;next; } }; . Odd-Even Linked List . Leetcode . Doing this problem in place is quite interesting. Since we want to separate out odd and even groups lets just maintain different pointers? In the end we shall link the lists. . class Solution { public: ListNode* oddEvenList(ListNode* head) { if(head==nullptr) return head; ListNode *even=head-&gt;next,*evenHead=head-&gt;next,*odd=head; while(even!= nullptr and even-&gt;next!=nullptr){ odd-&gt;next = odd-&gt;next-&gt;next; even-&gt;next = even-&gt;next-&gt;next; odd = odd-&gt;next; even = even-&gt;next; } odd-&gt;next = evenHead; return head; } }; . Intersection of Two Linked Lists . Leetcode . A simple solution would be to calculate the difference between their lengths and adjust the position of the pointers. . Can we do it without calculating the lengths? Well yes. Let’s say the length of A is a+c and of B is b+c. Lets say that A has covered a+c length, B has covered b+c length. They both shall meet when they have the same distance covered, so if the pointer of A goes to the head of B and same for the other, then both will cover a+c+b and b+c+a distance. They will meet at the intersection now. . class Solution { public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode *a=headA,*b=headB; while(a!=b){ a = a==nullptr ? headB : a-&gt;next; b = b==nullptr ? headA : b-&gt;next; } return a; } }; . Bit Manipulation . Single Number . Leetcode link . If we XOR a number with itself, it nulls out. So XOR all the numbers in the array and voila! . class Solution { public: int singleNumber(vector&lt;int&gt;&amp; nums) { int ans=0; for(int &amp;i:nums){ ans ^= i; } return ans; } }; . Single Number II . Leetcode | Solution reference . Of course we can use a dictionary, but can we do it in constant memory? We can, but it’s not that straightforward. . We’ll have to think of integers in terms of bits to solve this problem. . Aim: Develop a counter which . Resets after k elements | The counter should be unaffected by 0 | It should increment by 1 if it sees one | . class Solution { public: int singleNumber(vector&lt;int&gt;&amp; nums) { int x1=0,x2=0,mask; for(int i=0;i&lt;nums.size();i++){ x2 ^= x1 &amp; nums[i]; x1 ^= nums[i]; mask = ~(x1 &amp; x2); x1 &amp;= mask; x2 &amp;= mask; } return x1; } }; . Sum of Two Integers . Let’s take two numbers, 5 and 7. In base two, they’ll look like . 5 - 101 7 - 111 . Now there are two basic things we keep in mind . how to add numbers? | how to take care of carry? | . Now we cant use + or -, so we need to figure out an operator which would yield one with 1 and 0, but 0 with both 1 or both 0. The XOR gate nicely handles this case. . Carry only happens when both digits being added are 1. A good old AND gate will handle this case for us. . Now instead of conventionally adding and using carry together, why not simply add the numbers without carry, calculate the carry with the AND gate, shift it to the left, and then add that to the XOR result. . Take care of negative values: We try to represent negative vaules as unsigned int and then right shift, as right shift for negative isnt possible. . class Solution { public: int getSum(int a, int b) { if(a==0) return b; return getSum((unsigned int)(a&amp;b)&lt;&lt;1,a^b); } }; . My weak points . cpp string questions | dynamic programming | linked lists | .",
            "url": "https://rohanrajpal.com/interview/2020/06/18/DSA-interview-prep.html",
            "relUrl": "/interview/2020/06/18/DSA-interview-prep.html",
            "date": " • Jun 18, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Selective network routing or Split Tunneling via VPN",
            "content": "Everyone is working from home and for me it is remotely working on the servers in my college. I can only connect to them via a VPN, but that slows down my browsing and video conferencing. . I was trying to figure out a way to use VPN specifically for the server in college and let the other traffic move normally. That’s when I came across this solution. In this blog I’ll explain the solution step by step. . tl,dr : At the end of this blog you’ll be able to select which website or IP addresses you want to route through the VPN. . Requirements: . Ubuntu (Should work on other Linux distros as well) If you are using windows, this method works with Windows Subsystem for Linux. Do ensure that you have WSL2 before proceeding. | . | Openfortivpn Ensure that you can connect to a VPN using it. | . | . Steps for selective routing . 1. VPN configuration file . This file tells our VPN client the configuration of our VPN. . Save the below config file as vpn-config.conf anywhere on your computer . host = vpn.iiitd.edu.in port = 10443 username = &lt;your username&gt; password = &lt;your pass&gt; set-routes = 0 set-dns = 0 pppd-use-peerdns = 0 . set-routes = 0 specifies to not make any routes through the VPN, now we will whitelist the websites to use through the VPN. . 2. Setup the PPP script . What’s PPP?: PPP is Point to Point protocol. Linux uses this protocol to communicate over TCP/IP to your Internet Provider.read more . We are now going to write a script that will whitelist specific domains to pass through the VPN. . Use the following commands to create the script . sudo touch /etc/ppp/ip-up.d/fortivpn sudo chmod a+x /etc/ppp/ip-up.d/fortivpn . What’s pppd? The PPP Daemon (pppd) is a freely available implementation of the Point-to-Point Protocol (PPP) that runs on many Unix systems. read more . What’s ip-up? /etc/ppp/ip-up is a shell script executed by pppd when the link/internet comes up. read more . Edit the above script with your favourite editor, it shall look like: . #!/bin/bash # # Whitelist here all domains that need to go through openfortivpn # Domains and IPs are separated by a space # ips=&#39;192.168.2.217 192.168.29.151&#39; domains=&#39;example.com example.fr&#39; let resolved for domain in $domains; do resolved=`dig +short $domain | tail -n1` ips=&quot;$ips $resolved&quot; done for ip in $ips; do route add $ip dev ppp0 done . Now add the ips and domains you want to access through the VPN. . 3. Run the VPN . The following command should connect you to your VPN now. . sudo openfortivpn -c vpn-config.conf . Below you can see the routes added for the ip addresses. ppp0 is the vpn interface and enp2s0 is the ethernet. . rohan@rohan-laptop ~&gt; route (base) Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default _gateway 0.0.0.0 UG 100 0 0 enp2s0 one.one.one.one 0.0.0.0 255.255.255.255 UH 0 0 0 ppp0 103.25.231.4 0.0.0.0 255.255.255.255 UH 0 0 0 ppp0 link-local 0.0.0.0 255.255.0.0 U 1000 0 0 enp2s0 192.168.0.0 0.0.0.0 255.255.255.0 U 100 0 0 enp2s0 192.168.2.217 0.0.0.0 255.255.255.255 UH 0 0 0 ppp0 192.168.29.151 0.0.0.0 255.255.255.255 UH 0 0 0 ppp0 . That’s about it! You can now work on your server and enjoy fast internet along :) . Bonus: Automatically start VPN on boot . It’s quite irritating to log into the VPN everytime before starting work. So I created a system service to automatically connect to VPN on boot. Disclaimer: this will not work with WSL2 . Run these commands to setup the service . sudo touch /etc/systemd/system/openfortivpn.service . Open it with your favorite editor and enter this configuration. Thanks to DimitriPapadopoulos for helping me with it. . [Unit] Description = OpenFortiVPN After=network-online.target Documentation=man:openfortivpn(1) [Service] Type=idle ExecStart = /usr/bin/openfortivpn -c &lt;path to your config file&gt; StandardOutput=file:&lt;any-place-where you want to save your logs&gt; Restart=always RestartSec=10 [Install] WantedBy=multi-user.target . To start this service, simply run . sudo systemctl enable openfortivpn sudo systemctl start openfortivpn . To check if it is running . rohan@rohan-laptop ~&gt; sudo systemctl status openfortivpn ● openfortivpn.service - OpenFortiVPN Loaded: loaded (/etc/systemd/system/openfortivpn.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-04-25 13:22:26 IST; 3h 43min ago Docs: man:openfortivpn(1) Main PID: 1851 (openfortivpn) Tasks: 6 (limit: 4915) CGroup: /system.slice/openfortivpn.service ├─1851 /usr/bin/openfortivpn -c /home/rohan/Documents/vpn-configs/iiitd.conf └─1852 /usr/sbin/pppd 38400 :1.1.1.1 noipdefault noaccomp noauth default-asyncmap nopcomp Apr 25 13:22:26 rohan-laptop systemd[1]: Started OpenFortiVPN. Apr 25 13:22:26 rohan-laptop pppd[1852]: pppd 2.4.7 started by root, uid 0 Apr 25 13:22:26 rohan-laptop pppd[1852]: Using interface ppp0 Apr 25 13:22:26 rohan-laptop pppd[1852]: Connect: ppp0 &lt;--&gt; /dev/pts/0 Apr 25 13:22:27 rohan-laptop pppd[1852]: local IP address 10.212.134.101 Apr 25 13:22:27 rohan-laptop pppd[1852]: remote IP address 1.1.1.1 . Thanks for reading :) If this did help you, feels free to like, comment and share this blog. . References . openfortivpn | ppp | ppp daemon | thumbnail image | .",
            "url": "https://rohanrajpal.com/2020/04/25/Selective-network-routing.html",
            "relUrl": "/2020/04/25/Selective-network-routing.html",
            "date": " • Apr 25, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "DMRC Connect: Improve your daily commute",
            "content": "From July-November 2019, my team and I worked on an application. This project was a part of the course: CSE501-Designing Human-Centered Systems. . DMRC-Connect Media Coverage . We were glad that our project was covered by various news channels. Click on any of the images below to read more: . Our project featured in news Motivation . The metro has been the backbone of transport in Delhi NCR, with daily ridership in excess of 5 million riders. It is famous for providing world-class transit with reach to almost all corners of the city with a reputation of punctuality and quality. At the core of these values lie the vision and mission of DMRC that aim to have the best possible experience for riders from all walks of life and have that with trust and reliability. . DMRC has always tried to take an extra step ahead to connect better with the riders and provide them with the best experience. Social media plays an important role in their endeavour to build this connection, with DMRC being active on all social media platforms and constantly engaging with the riders. . Red Line UpdateDelay in service from Shastri Park towards Dilshad Garden due to a passenger on track at Welcome.Normal service on all other lines. . &mdash; Delhi Metro Rail Corporation I कृपया मास्क पहनें😷 (@OfficialDMRC) August 5, 2019 Hi. Metro services shall be resumed as per government directions. We shall update the information on our social media channels. Thank You! . &mdash; Delhi Metro Rail Corporation I कृपया मास्क पहनें😷 (@OfficialDMRC) June 12, 2020 However, the question remains, do all Delhi metro users really use Twitter? While DMRC is putting in full efforts to relay this information to riders, is it really reaching the intended audience? Are complaints being solved fast enough for affected riders to benefit from it? Do all complaints be it from Twitter, or from their helplines come with complete information? . Unfortunately, a general trend after rolling out small surveys and talking to users at various metro stations and in and around Delhi, we got to know that this wasn’t the case. Not only was social media outreach restricted to those who followed DMRC on Twitter, but this sort of engagement also was never advertised or encouraged by any official metro source. . Problem Statement . What does DMRC Connect do? . We create an application that facilitates interaction between DMRC officials and DMRC users and bridges the gap created earlier due to less outreach. . What are the features? . Sticking to the theme of the user and official interaction, the features of DMRC Connect are: . Announcements | Complaint registration | Complaint tracking | Quick access helplines | FAQs | The Design Process . Contextual Enquiry . To help understand the problem better and get the user’s perspective on it, we set out to interview general metro users about their usage patterns and general behaviour when it comes to complaints. Our aim was to understand the kind of behaviour users have while interacting with current systems and understand whether the current modes of communication were effective or not. . The target audience was any general rider of the metro who was not a minor, and questions ranged from general ones that helped us understand their general behaviour towards tackling issues they faced, to more specific ones that asked the user about their experiences specific to the metro. . A few of the questions were: . How often do you face “issues” or “problems” in services offered to you? It could be in an app, it could be during transportation like railway/metro/bus, it could be college or conferences? | Have you ever come across official announcements from Delhi metro? Where did you hear about them? | What problems have you faced in the metro till now? Can you describe any one instance? | . Lo-Fidelity Prototypes . Based on the affinity mapping, we came up with the initial paper prototypes of our application and took them to users for testing through Task Analysis. . . Key Findings from v0 and v1: . Users went to “Help Centre” to do most tasks related to getting help from DMRC, very few users went to the actual intended target location. | “Contact Us” seemed to be a way to contact the developers rather than DMRC helplines. | Some people went to the complaint section in v2 to find women’s helpline. | In helplines, instead of direct calls, users wanted phone numbers to pop-up instead. | Hi-Fidelity Prototypes . After 3 iterations of user testing through Task analysis on the lo-fidelity prototypes, we arrived at the first version of the hi-fidelity prototype and conducted testing on it. . High Fidelity prototypes One of the major changes after user testing on the Hi-Fidelity prototype was to change the colour scheme to one with less hue, i.e primarily blue-based instead of red-based, and to shift from side navigation to bottom navigation instead. . Final Color Scheme and Typography . The typography used throughout was Roboto, as it is standardly used by Google and the colour scheme is mentioned below. . . Final Application . The final application, made with help of Android Studio and a Flask backend, was made live on the play store for users to use. The application is available here. However, due to lack of resources, we have closed the backend for now. . The final application DMRC Connect is now Open Source! . We have released the source code on github. Feel free to clone and play around with it! https://github.com/gupta-meghna64/DMRC-Connect . Building Better Interfaces #BBI2019 . Team members . Rohan Rajpal https://github.com/rohanrajpal | Meghna Gupta https://github.com/gupta-meghna64 | Saatvik Jain https://github.com/saatvikj | Tanya Gupta https://github.com/Tanya16107 | Siddharth Yadav https://github.com/sedflix | .",
            "url": "https://rohanrajpal.com/mobile/2019/11/15/DMRC-Connect.html",
            "relUrl": "/mobile/2019/11/15/DMRC-Connect.html",
            "date": " • Nov 15, 2019"
        }
        
    
  
    
        ,"post13": {
            "title": "My GSoC experience with VideoLAN: Redesigning the VLC media player",
            "content": "Introduction . This summer, I participated as a Google Summer of Code student under VideoLAN. GSoC is undoubtedly one of the best summer programs out there. From designing interfaces and interactions to writing production-level code, I’ve learned tons of exciting stuff! I was blessed to have great mentors and learned a lot about the open-source community. . Project and Proposal . The VLC media player has an Editor which enables you to customize the player controlbar UI; you can arrange buttons like the play button as per your liking. My main task was to implement this Editor functionality in the new UI for VLC. . You can have a look at my project page on the GSoC website. Feel free to check out my proposal. . Patches . I made an account on VideoLAN’s Gitlab and worked on this repository. I used to push all my commits there to get them reviewed. Then made patches out of them and sent commits to the VLC-developer mailing list. A few other people would then review the patches. Finally, after making the required changes, the patches would get merged. . Here is a list of all my patches. . The Team . A big thanks to the team and my mentors who helped me with my endless doubts! . Abel Tesfaye (GSoC Student) | Sagar Kohli (GSoC Student) | Jean-Baptiste Kempf (VideoLAN president) | Pierre Lamot (Software engineer at Videolabs) | Alexandre Janniaux (Software engineer at Videolabs) | Rohan Rajpal (Me) | . Our communication was mainly via emails and #vlc-gsoc on IRC. . The Project . What work was done? . I had made some contributions towards the player controlbar and further wanted to work on it. Jean then suggested I should work on the Editor. Making the Editor was a big task to do, we divided it into the following parts: . Create a model of all the buttons/widgets on the player ControlBar. | Load the player buttons from the model instead of hardcoding them. | Make a simple drag and drop interface which changes the model by dragging and dropping and updates the config | Make a View from which you can drag and add buttons to the player ControlBar. | Add profiles combobox via which you can load, make and delete configurations for the player. | Populate the miniplayer from the model | Make miniplayer editable and add a tab for it in the editor | I have also worked on a few other things . Add all the missing buttons and widgets. I’ve added the following: Volume Widget | Teletext Widget | Aspect Ratio widget | Record button | Spacer widget | Extended Spacer widget | FullScreen button | Record button | AB Loop button | Snapshot button | Stop button | Media Info button | Frame by frame button | Faster button | Slower button | Open media button | Extended settings button | Step forward button | Step backward button | Quit button | . | Create a topbar for non editable buttons | What’s left to do? . Although I completed every task I was assigned, below-mentioned tasks are best suited as a follow-up for my work done: . If too many widgets come on one side the center buttons don’t remain in the center anymore. This has to be fixed. | The design of the Teletext and a few other widgets isn’t final and work needs to be done. | Demo . Have a look on how the VLC Editor works below: . Highlights and Challenges . Make a generic player controlbar . The first task was to make a model that had all the button and widget data. Then I had to use that model to populate the player ControlBar. Loaders are quite helpful when you have to load a component in QML. . Loader { id: myLoader source: &quot;MyItem.qml&quot; } . After making the buttons model. The next step was to make a QtAbstractListModel to maintain a list of the buttons in current config. This is how the player ControlBar is populated now: . The model would load the config from VLC Core API. | The player controlbar model would then add the respective buttons to the list. | The main controlbar would then use this model to get the list and ids which would then load the button from the buttons model. | . Make sure VLC is accessible via keyboard . One had to make sure that VLC is easily useable via the Keyboard as well. KeyNavigation and Focuscope are the critical things you’ll work with when you are working with Focus. . With a lot of documentation reading, experimenting, and Pierre’s help, I successfully got the KeyNavigation right. . Drag and Drop . We all use drag and drop interfaces quite frequently. Making such interfaces made me understand the design and the logic behind it. . To make an item draggable, you have to set it as a drag target. Similarly, to make it possible to drop a draggable, you need to declare a DropArea. . I also had to add functionalities like move, insert and delete to the model, because Drag and Drop involve all these actions. Have a look at some of the actions below: . The next task was to code the cancel and close buttons. The player controlbar should only be updated when the user presses the close button. To implement this, I used signals. . When you press the close button, the toolbarConfUpdated signal emits, and the playerControlBar is updated. . Signals and Slots are used for communication between objects in Qt. Here’s the signal sent when toolbar is updated: . if( toolbarEditor-&gt;exec() == QDialog::Accepted ) emit toolBarConfUpdated(); . Hinting the user . For the user to easily use the drag and drop interface, we have to provide some hints. When you hover over a draggable item, the cursor changes to an open hand cursor. If you click and hold over it, the cursor changes to a closed hand cursor. The cursor changes to ForbiddenCursor if you take the draggable to a place where it’s not possible to drop. . Profiles . Profiles help someone easily save their preferences. For this, I kept the configs of both the player and the mini-player controlbar and split them using a delimiter. . Different parts of the Editor . One interesting thing about this editor is that it is a mix of QML and Qt/C++. The window, profiles section and action buttons are coded in Qt. The whole drag and drop part is in QML. . Why use Qt when all can be done in QML? Because: . qml takes more ram | qml accessibility is hard to get | qml is harder to debug, and helps doing some big qml files, which we want to avoid at all cost. | . The picture below shows the division. . Things I learned . Git Tricks like fixup and autosquash help a lot in keeping the commits clean. | Rebase and reset is quite helpful when you need to edit or rearrange commits. | How to work with patches, send emails from git directly. | Handling merge conflicts like a pro. | How to split commits? A nice trick is if the commit message has bullet points, it can further be split. | . | Code Avoid writing over-engineered code | How to work on a huge codebase. Things like Memory leaks, ram consumption, learned how to use the VLC Core API. | Design patterns like the D-pointer strategy and Model View Delegate. | Qt/C++, QML and writing production-level code in them. | QtCreator, one of the best IDEs I’ve used. | . | Design Learned design concepts like form follows the flow. | Prototyping, brainstorming on interactions. | Clipping | Thinking design solutions keeping the code in mind. | . | .",
            "url": "https://rohanrajpal.com/gsoc/2019/08/12/GSoC-with-VideoLAN.html",
            "relUrl": "/gsoc/2019/08/12/GSoC-with-VideoLAN.html",
            "date": " • Aug 12, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". I’m a third-year CSE student at IIITD, a Google Summer of Code 2019 student under VideoLAN and an intern at Expedia for Summer 2020. . My expertise lies in Cloud (AWS,GCP,Spark,Vault), Frontend(Qt,HTML/CSS,Unity), Database (MongoDB, Elasticsearch, SQL, Logstash) and Deep Learning (mainly Computer Vision). . Here is my Resume. . Notable Coursework at IIITD . Deep Learning | Wearable Applications, Research, Devices, Interactions | Machine Learning | Computer Networks | Designing Human-Centered Systems | Analysis and Design of Algorithms | Database Management System | Advanced Programming | Discrete Maths | Operating Systems | Data Structures and Algorithms | Probability and Statistics | Linear Algebra | . Engineering . Some of my coursework projects include: . Implementing the Go-Back-N protocol in Python | Simulating a computer network using ns-3 and evaluate its performance in C++ | Find diseases in crops using computer vision and deep learning techniques (Pytorch,Fastai). | Find patterns in shallow clouds using satellite imagery using deep learning techniques (Pytorch,Fastai). | Implementing demand paging in Xv6 in C | Implementing priority scheduling in Pintos in C | Implement a custom Linux shell using C | Implementing a Merkle tree in C | Made a replica of the popular Snake Vs Block using Java and JavaFX | . Independent projects: . I wrote a recommender system for movies. Implemented user-user and item-item collaborative filtering in Python. Used Flask, Javascript to build the web app and deployed it to Heroku. | Made a mini-ERP system, an Android app in Java using Firebase for handling the data | . Research . Undergraduate Researcher, Precog. The social computing lab of IIITD. | Working on analyzing the social media data of an Indian app. Characterizing the role of the NaMo app in shaping political discourse on social media | Fuzzy matching at scale, TF-IDF matrices cosine similarity, Elasticsearch | . Community and Leadership . I like contributing to the community, here’s what I’m trying to do from my side: . Lead and founder, Developer Students Club of IIITD. | Mentor, Student Mentorship Programme: Mentoring 7 freshmen and helping them with their academic, social and personal issues. | . | . Feel free to connect with me on LinkedIn. . Questions and Answers . Tell us about an accomplishment you’re most proud of, and why it makes you proud . In my internship these summers, I worked in the cloud domain. My team was migrating from a legacy stack, and re-architecting for the cloud. My project involved building a spark job to sync data between different platforms. I found the work to be quite overwhelming at the start. I didn’t have much experience about technologies like Apache Spark, Hashicorp Vault, AWS. We also never really learnt much about scalability during college, so I had to learn about these concepts from scratch. However, I really wanted to learn more about the cloud and decided to give in my best. I delivered the proof of concept in just two weeks, and by the end of my internship, I had developed a scalable and secure production-level application. I exceeded the expectations of my team and received excellent feedback about my work. I had come in with a straightforward aim for my eight-week internship; I wanted to ship industry-standard code. It was quite challenging, but I am proud that I achieved it. . You can know more about my project here . Tell us about a problem that frustrates you, and why it frustrates you . I find it frustrating when people try to make money by offering interview prep courses at exorbitant prices just because they have worked at a tech giant or got admit in an ivy league college. I believe that quality education should be accessible to anyone for 10 dollars or less. In our country, the situation is even worse. We all have to give an entrance exam to get into engineering colleges, and we get an admission solely on our rank on the test, nothing else. These exams are so competitive that people have set up coaching institutes which prepares students only for this single exam, starting as much as six years before the exam! The fees they charge for this is in multiples of the high school tuition fee. It’s not fair to capitalize on the fear of students to not be able to get into a decent college. . Tell us about a hack you’ve built . Many founders are scrappy and solve problems quickly with limited resources. What’s a problem that you’ve encountered in your life where you’ve “hacked” together a physical, technical, or system-level solution? . When the pandemic started, everyone had to work from home. For corporates and schools, this meant a massive increase in VPN use, leading to slower internet speeds. I had to connect to a VPN almost every time, and the slow VPN speeds significantly affected browsing and video call experience. I just wanted a way I can use the VPN only for the server. So I finally figured out a way to selectively use VPN only for servers and use other applications without any restrictions. I shared my approach in a blog with my friends, and they found it quite useful, I have been using this split VPN approach ever since then. . Here’s the approach . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rohanrajpal.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  
      ,"page7": {
          "title": "Support Me",
          "content": ". I try to take the assignments and learnings from my projects, courses, internships, and convert them into nice blog tutorials. . If you would like to support my work, you can buy me a coffee ☕. Thanks for visiting 😄. .",
          "url": "https://rohanrajpal.com/support-me/",
          "relUrl": "/support-me/",
          "date": ""
      }
      
  

  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rohanrajpal.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}