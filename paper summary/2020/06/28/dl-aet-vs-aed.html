<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data | Rohan Rajpal · Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019." />
<meta property="og:description" content="Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019." />
<link rel="canonical" href="https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html" />
<meta property="og:url" content="https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html" />
<meta property="og:site_name" content="Rohan Rajpal · Blog" />
<meta property="og:image" content="https://rohanrajpal.com/images/paper-summary/aet-vs-aed.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-28T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data","dateModified":"2020-06-28T00:00:00-05:00","datePublished":"2020-06-28T00:00:00-05:00","description":"Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html"},"@type":"BlogPosting","image":"https://rohanrajpal.com/images/paper-summary/aet-vs-aed.png","url":"https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rohanrajpal.com/feed.xml" title="Rohan Rajpal · Blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-145665153-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data | Rohan Rajpal · Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019." />
<meta property="og:description" content="Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019." />
<link rel="canonical" href="https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html" />
<meta property="og:url" content="https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html" />
<meta property="og:site_name" content="Rohan Rajpal · Blog" />
<meta property="og:image" content="https://rohanrajpal.com/images/paper-summary/aet-vs-aed.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-28T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data","dateModified":"2020-06-28T00:00:00-05:00","datePublished":"2020-06-28T00:00:00-05:00","description":"Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html"},"@type":"BlogPosting","image":"https://rohanrajpal.com/images/paper-summary/aet-vs-aed.png","url":"https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://rohanrajpal.com/feed.xml" title="Rohan Rajpal · Blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-145665153-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/">Rohan Rajpal · Blog</a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
  
          <div class="trigger">
            <a class="page-link" href="/resume/Rohan_Resume.pdf">Resume</a><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/support-me/">Support Me</a><a class="page-link" href="/categories/">Tags</a></div>
        </nav></div>
  </header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Paper Summary: AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-28T00:00:00-05:00" itemprop="datePublished">
        Jun 28, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Paper Summary">Paper Summary</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <blockquote>
  <p>Zhang, Liheng, et al. “Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.</p>
</blockquote>

<p>Deep Learning has had phenomenal success in computer vision tasks. However, one requires a large amount of labelled data to extract good enough representations. That is why its challenging to use Deep Learning with a short amount of labelled data. However, there has been recent research using unsupervised methods to develop representations of data.</p>

<p>Till date, the methods in unsupervised representation learning try to Auto Encode Data (AED). This paper explores the dynamics of feature representations under different transformations by Auto Encoding Transformations (AET) instead of data. They realise that as long as an unsupervised model learns sufficiently informative representations of the original and the transformed image, a model can decode the transformation.</p>

<p><img src="/images/paper-summary/aet-vs-aed.png" alt="" /></p>

<p>They present an AET paradigm which allows us to instantiate a wide range of operators which include parameterised, non-parameterized and GAN-induced transformations. AET achieves state-of-the-art performances on Imagenet, CIFAR-10 and Places dataset. Additionally, its results demonstrate an accuracy close to the cap set by its supervised counterparts. Further analysis of AET loss with accuracy and error plots reveals predictions of transformations are a good indicator for better classification results.</p>

<p>In their method, they predict the transformation from the representations of the original and transformed image. To predict parametric transformations, they use a loss function based on the difference of the parameters of the transformation. For GAN-Induced transformations, they calculate the difference between the noise parameters for the loss function. Finally, for non-parametric transformations, they measure the average distance between the transformations and the randomly sampled images.</p>

<p>To evaluate the model, they build a classifier on top of the architecture they use for a dataset. They test their model on the CIFAR-10, Imagenet and the Places dataset. In the CIFAR-10 experiment, they adopt a Network in Network (NIN) architecture which they train by SGD with a composition of transformations. For classification, they use a model-based and a model-free classifier. For the model-based classifier, they build a non-linear classifier with three FC layers. The model-free classifier is a KNN classifier based on the average pooled features from the second convolutional block. The AET outperforms all the other unsupervised methods. Additionally, with the convolutional classifier, AET performs almost similar to fully supervised NIN architecture. However, a direct comparison between AET and other experiments is difficult, as other methods have different architectures and hyperparameters. In the Imagenet dataset, they take two AlexNet branches with its 1000-way linear classifier. They achieve the best results among the other unsupervised models. In the places dataset, they assess the generalisability of their representations by using the previous architecture pretrained on Imagenet. They achieve the best results except in a few scenarios.</p>

<p>Although AET gets impressive results, the motivation to encode transformations instead of data isn’t clear and scattered throughout the paper. Also, all of their results are based on parametric transformations because they couldn’t get as good results with other operators. However, they couldn’t concretise on why other transformations didn’t work well.
The paper presents an excellent motivation to improve unsupervised methods of learning. They explain their methods and evaluations in-detail and use ablations to find out the exact reasons. Along with the advantages, they also highlight the drawbacks of their approach, providing a balanced view. However, it was hard to understand the motivation to learn transformations instead of data. Bringing together the motivation for transformations in the introduction would have explained their approach better.</p>

  </div>
  Thanks for reading 😄. Want to learn more? <a href="https://rohanrajpal.substack.com/">subscribe to my newsletter</a>.<div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html';
      this.page.identifier = 'https://rohanrajpal.com/paper%20summary/2020/06/28/dl-aet-vs-aed.html';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://https-rohanrajpal-github-io.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/paper%20summary/2020/06/28/dl-aet-vs-aed.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Read about Data Science · Programming · Design · Mobile</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/rohanrajpal" title="rohanrajpal"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.instagram.com/rohan__rajpal" title="rohan__rajpal"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#instagram"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/rohanrajpal" title="rohanrajpal"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rohan__rajpal" title="rohan__rajpal"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
